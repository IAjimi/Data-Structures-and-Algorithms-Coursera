#### WEEK 3 ####
def min_coin_number(_input):
	coins_number = 0

	for n in [10, 5]:
		coins_number += _input // n
		_input = _input % n

	return coins_number + _input

def fractional_knapsack(W, v1, w1, v1, w2):
	# Read Input

	unit_value = [v[i]/w[i] for i in range(len(v))]
	
	# Sort unit_value, w
	sorted_uv_idx = sorted(range(len(unit_value)),key=lambda x:unit_value[w], reverse = True)
	w = [w[i] for i in sorted_uv_idx ]
	unit_value.sort()

	# Iterate over sorted list
	for i in unit_value:
		if W == 0:
			return round(V, 4)
		else:
			a = min(w, W)
			V += a * v / w
			w += - a
			W += -a

def min_refuels(d, m, n, stops):
    num_refills = 0
    current_refill = 0
    stops = [0] + stops

    while current_refill <= n:
        last_refill = current_refill

        if (stops[current_refill + 1] - stops[last_refill] > m): return -1 # unreachable next spot (needs to be after latest assignment of last_refill)
        
        while (current_refill <= n) and (stops[current_refill + 1] - stops[last_refill] <= m): # keep going, if > m then you need to refuel
            if (stops[current_refill] + m >= d): return num_refills + 1 # you can reach the end from here
            current_refill += 1
        
        num_refills += 1

    return num_refills

# 500
# 200
# 4
# 100 200 300 400
# -> 2

## COLLECTING SIGNATURES
# n segments, find minimum of points m s.t. each segment contains a point

# 3 <- n segments
# 1 3 <- [1, 3]
# 2 5
# 3 6
## -> 1 
## 3

# 4
# 4 7
# 1 3
# 2 5
# 5 6
## 2 
## 3 6


## -> pick rightmost point in leftmost segment


## MAXIMUM NUMBER OF PRIZES
# one integer n
# the maximum k s.t. n = a1 + a2 + ... + ak where every ai different

def max_number_prizes(n):
	counter = 0
	_sum = 0
	numbers = []

	for i in range(1, n):
		if _sum + i + (i + 1) > n:
			numbers.append(n - _sum)
			return counter + 1, numbers
		else:
			counter += 1
			_sum += i
			numbers.append(i)

	return counter, numbers

## MAXIMUM NUMBER
# compose largest number out of a set of integers

# 2
# 21 2
## 221

def maximum_number(numbers):
	numbers.sort(reverse = True)
	numbers = [str(n) for n in numbers]
	max_number = ''.join(numbers)

	return int(max_number)

#### WEEK 4 ####
## DIVIDE AND CONQUER
Break down problem into smaller subproblems of the
same type. Since each subproblem is similar to the
orgiinal problem, divide & conquer algorithms naturally
lead to a RECURSIVE solution.

# LINEAR SEARCH
Searching in an unsorted array using linear search, i.e.,
go through the array 1 by 1 and check if element you are
looking for is there.

LinearSearch(A, low, high, key):
	'''Basically check 1st element of array
	between low and high. If not it, perform
	LS on array without 1st element in prev 
	array.'''
	if high < low:
		return NOT_FOUND
	if A[low] = key:
		return low
	return LinearSearch(A, low+1, high, key)

Worst-case runtime? T(n) = T(n-1) + c = n * c
(c is a constant amount of work, for checking high < low and
A[low] = key)

# FIBONACCI RECURRENCE RELATION
Important to handle base case! n = 0, n = 1

# BINARY SEARCH
INPUT: A sorted array, A[low ... high]. A key k.
OUTPUT: An index i where A[i] = k. Otherwise, the
greatest index i where A[i] < k. Otherwise (k < A[low]),
the result is low - 1.

(The list is sorted - so if the 1st element is > k,
k is not in the list. Similarly, if the last element
is < k, then k is not in the list - index would be > length.)

EX.
[3, 5, 8, 20, 20, 50, 60]
search(2) -> 0
search(3) -> 1
search(4) -> 1
search(20) -> 4 OR 5
search(60) -> 7
search(90) -> 7

BinarySearch(A, low, high, key):
	if high < low: #empty array
		return low - 1

	mid <- floor(low + (high-low) / 2)

	if key = A[mid]
		return mid
	elif key < A[mid]:
		return BinarySearch(A, low, mid - 1, key)
	else:
		return BinarySearch(A, mid + 1, high, key)

EX: RecursiveBinarySearch(A, 1, 11, 50)
A = [3, 5, 8, 10, 12, 15, 18, 20, 20, 50, 60]
1st mid is 6. 50 > A[6] so BinarySearch(A, 7, 11, 50).
Mid is 9. 50 > A[9] = 20 so BinarySearch(A, 10, 11, 50).
Mid is 10. 50 = A[10] so return 10.

Worst-case runtime? T(n) = T(floor(n/2)) + c
-> O(log_2 n)

IterativeBinarySearch(A, low, high, key):
	while low <= high:
		mid <- floor(low + (high - low) / 2)

		if key = A[mid]:
			return mid
		elif key < A[mid]:
			high = mid - 1
		else:
			low = mid + 1

	return low - 1

# POLYNOMIAL MULTIPLICATION
EX: 
A(x) = 3x**2 + 2x + 5
B(x) = 5x**2 + x + 2
A(x)B(x) = 15x**4 + 13x**3 + 33x**2 + 9x + 10

INPUT: n = 3, A = [3, 2, 5], B = [5, 1, 2]
OUTPUT: [15, 13, 33, 9, 10]

# Naive Approach
MultPoly(A, B, n):
	product = [0 for i in range(2n-1)]

	for i in range(n-1):
		for j in range(n-1):
			product[i+j] = product[i+j] + A[i] * B[j]

	return product

runtime is O(n**2) because a double for loop

# Naive Divide and Conquer
Let A(x) = D(x)x**(n/2) + D0(x)
Let B(x) = E(x)x**(n/2) + E0(x)
AB = (Dx**n/2 + D0)(Ex**(n/2) + E0) 
= (D1E1)x**n + ...

Yields 4 polynomials of degree n/2.

EXAMPLE:
A = 4x**3 + 3x**2 + 2x + 1
B = x**3 + 2x**2 + 3x + 4

D1 = 4x + 3
D0 = 2x + 1
E1 = x + 2
E0 = 3x + 4

-> Compute D1E1, D1E0, D0E1, D0E0.

Then AB = (D1E1) x ** 4 + (D1E0+D0E1) x ** 2 + D0E0

Mult2(A, B, a, b):
	R = [0 for 0 in range(2n-1)]

	if n == 1:
		R[0] = A[a] * B[b]
		return R
	else:
		R[:n-2] = Mult2(A, B, n/2, a, b)
		R[n:2n-2] = Mult2(A, B, n/2, a + n/2, b + n/2)

		D0E1 = Mult2(A, B, n/2, a, b + n/2)
		D1E0 = Mult2(A, B, n/2, a + n/2, b)

		R[n/2:n+n/2-2] += D1E0 + D0E1

		return R

# FASTER DIVIDE AND CONQUER ALGORITHM
A(x) = a_1*x + a_0
B(x) = b_1*x + b_0
C(x) = a_1*b_1*x**2 + (a1*b0 + a0*b1)*x + a0*b0
-> needs 4 multiplications

rewrite as:
C(x) = a_1*b_1*x**2 + ((a1+a0)*(b1+b0) - a1b1 - a0b0)*x + a0*b0

some math leads to the conclusion that the runtime that this is
O(n**1.58)

# MASTER THEOREM
Formula:
If T(n) = aT(floor(n/b)) + O(n**d) for a > 0, b > 1, d >= 0
then
	if d > log_b(a) then O(n**d)
	if d = log_b(a) then O(n**d log(n))
	if d < log_b(a) then O(n**log_b(a))

EX: T(n) = 4 T(n/2) + O(n)
a = 4, b = 2, d = 1
since d < log_b(a), T(n) = O(log_b(a)) = O(n**2)

....

# SORTING PROBLEM
INPUT: A[1, ..., n]
OUTPUT: A[1, ..., n] in non-decreasing order

# EXAMPLE: SELECTION SORT
INITIAL ARRAY: [8, 4, 2, 5, 2]
STEP 1: find minimum (2), swap with 1st element
	-> [2, 4, 8, 5, 2]
STEP 2: repeat with remaining part of array [4, 8, 5, 2]
	-> [2, 2, 8, 5, 4]
ETC

SelectionSort(A):
	for i in range(1, n):
		minIndex = i

		for j from i + 1 to n:
			if A[j] < A[minIndex]:
				minIndex = j

		A[minIndex] = min(A[i:])
		A[i], A[minIndex] =  A[minIndex], A[i]

Run time? Outer loop runs n times but inner loop size decreases by 1
every time. O(n**2) time.

# MERGE SORT
1. [7, 2, 5, 3, 7, 13, 1, 6]

2. split into two halves
[7, 2, 5, 3], [7, 13, 1, 6]

3. sort the halves recursively
[2, 3, 5, 7], [1, 6, 7, 13]

4. take minimum, put in result array
[2, 3, 5, 7], [6, 7, 13]
[1]

5. repeat

MergeSort(A):
	n = len(A)

	if n == 1:
		return A

	m = floor(n / 2)
	B = MergeSort(A[:m])
	C = MergeSort(A[m+1:])
	A = Merge(B, C)

	return A

Merge(B, C):
	''' B and C are sorted.
	B is of length p, C is of length q.'''

	n = 0 # position counter
	D = [0 for r in range(p+q)]

	while B and C:
		b = B[0]
		c = C[0]

		if b <= c:
			D[n] = b
			B.pop(0)
		else:
			D[n] = c
			C.pop(0)

		n += 1

	# move the rest of B and C to the end of D

	return D

Runtime of Merge is p + q.
Runtime of MergeSort is O(n log n).

# LOWER BOUND FOR COMPARISON BASED SORTING ALGORITHM
A comparison based sorting algorithm sorts objects by
comparing paris of them. The selection sort and merge sort
algorithms are comparison based.

Any comparison based sorting algorithm performs Omega(n log n)
comparisons in the worst case to sort n objects.

There are n factorial "leaves" in the tree, for every permutation of 2
elements. The maximum number of comparisons is at least the depth d.
d >= log_2(l) 
so log_2(n!) = omega(n log n)

# Non-Comparison Based Sorting Algorithms
COUNTING SORT ALGORITHM
EX: Original array [2, 3, 2, 1, 3, 2, 2, 3, 2, 2, 1]
Count appearances of each object: {1:2, 2:7, 3:3}
Then: sorted array is [1, 1, 2, 2, 2, ..., 3, 3, 3]

For arrays of small integers.

# QUICK SORT
A = [6, 4, 8, 2, 9, 3, 9, 4, 7, 6, 1]

Pick first element, 6. Move 6 to its final position by moving all 
elements <= 6 to the left of 6 and > 6 to the right of 6.
A = [1, 4, 2, 3, 4, 6, 6, 9, 7, 8, 9]

Then, sort the two parts recursively.

QuickSort(A, l, r):
	if l >= r: # size?
		return
	m = Partition(A, l, r)
	# A[m] is in final position
	QuickSort(A, l, m - 1)
	QuickSort(A, m + 1, r)

Partitioning Example
pivot is x = A[l]
move i from l + 1 to r maintaining the following invariant:
*	A[k] <= x for all l + 1 <= k <= j
*	A[k] > x for all j + 1 <= k <= i

EX: [6, 4, 2, 3, 9, 8, 9, 4, 7, 6, 1] where x = 6
    [0, r, r, j, b, i, 0, 0, 0, 0, 0]
increment i + 1, new element is 9 > 6 so extend blue region
    [0, r, r, j, b, b, i, 0, 0, 0, 0]
increment, new element is 4, swap 1st element of blue region w 4
	[6, 4, 2, 3, 4, 8, 9, 9, 7, 6, 1]
    [0, r, r, r, j, b, b, b, i, 0, 0]
etc until
	[6, 4, 2, 3, 4, 6, 1, 9, 7, 8, 9]
    [0, r, r, r, r, r, j, b, b, b, i]
swap 6 with last element of red region, 1
final array:
	[1, 4, 2, 3, 4, 6, 6, 9, 7, 8, 9]

Partition(A, l, r):
	x = A[l] # pivot
	j = l

	for i in range(l + 1, r): # check new element
		if A[i] <= x: # if <= x, move to left region
			j += 1
			swap A[j] and A[i]
		# A[l + 1 ... j] <= x, A[j + 1 ... i] > x

	swap A[l] and A[j]
	return j

# RANDOM PIVOT
Worst-case: T(n) = n + T(n - 1) = n + (n - 1) + (n - 2) + ... = O(n**2)

What if we partitioned s.t. that one side is size 5 and the other is size 4?
T(n) = n + T(n - 5) + T(4) >= n + (n - 5) + (n - 10) + ... = O(n**2)

What if we partitioned into 2 arrays of equal size?
T(n) = 2 T(n / 2) + n = O(n log(n))

We want a way to select a pivot element so that it always guarantees a 
balanced partition. Not clear how to do this: instead, pick a random pivot.

Why random? half of the elements of A guarantee a balanced partition.

RandomizedQuickSort(A, l, r):
	if l >= r: # size?
		return
	k = random number between l and r
	swap A[l] and A[k]
	m = Partition(A, l, r)
	# A[m] is in final position
	QuickSort(A, l, m - 1)
	QuickSort(A, m + 1, r)

Assume that all elements of A[1 ... n] are pairwise different. Then the average
running time of RandomizedQuickSort(A) is O(n log(n)) while the worst running
time is O(n**2).


#### WEEK 5 ####
DYNAMIC PROGRAMMING
What is the min number of coins needed to change x cents
for denominations 6, 5, and 1?

Starting from left of array A
A = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
MinNumCoins = [0, 1, 2, 3, 4, 1, 1, 2, 3, 4]

at 5 cents, min(MinNumCoins(0) + 1, MinNumCoins(4) + 1)
at 6 cents, min(MinNumCoins(0) + 1, MinNumCoins(5) + 1, ...)

DPChange(money, coins):
	MinNumCoins(0) = 0

	for m in range(1, money):
		for i in range(1, len(coins)):
			if m >= coin[i]:
				NumCoins = MinNumCoins(m - coin[i]) + 1

				if NumCoins < MinNumCoins(m):
					MinNumCoins(m) = NumCoins

	return MinNumCoins(money)


# The Alignment Game
Remove all symbols from two strings in such a way that 
the number of points is maximized.

Remove the 1st symbol from both strings:
	1 point if the symbols match
	0 points if they don't match
Remove the 1st symbol from one of the strings: 
	0 points

x = [A, T, G, T, T, A, T, A]
y = [A, T, C, G, T, C, C]

remove 1st two

then remove C from y
x = [-, G, T, T, A, T, A]
y = [C, G, T, C, C]

then remove
x = [T, A, T, A]
y = [C, C]

end score of 4

--> 
alignment of two strings is a two row matrix
1 row w/ symbols of the 1st string (in order) interspaced by '-'
2nd row .... 2nd string w/ /// '-'

after playing, we can classify columns as
matches
insertions
deletions
mismatches

then we can give premium fr every match (+1)
penalty for every mismatch (-m)
penalty for every insertion or deletion (-o)

common subsequence - matches in an alignment of two strings
longest common subsequence -> maximizing alignment score
with m = o = 0

edit distance - min number of operations (insertions,
deletions and substitution) to transform one string
into another
--> equivalent to MAXIMIZING alignment score

Let D(i, j) be the edit distance of an i-prefix A[1 ... i]
and a j-prefix B[1 ... j].

D(i, j) = min( 
	D(i, j - 1) + 1, # insertion -> element in B, not A
	D(i - 1, j) + 1, # deletion -> element in A, not B
	D(i - 1, j - 1) + 1 # mismatch, if A[i] != B[j]
	D(i - 1, j - 1) # match, if A[i] == B[j]
	)

In other words, D(i, j) depends on D(i - 1, j - 1),
D(i - 1, j) and D(i, j - 1), each of which map to an operation.

Recall: the +1 are penalty scores. 
Starting from the VERY END of a theoretical optimal arrangement
and going backwards thru recursion OR moving forward from 0,0
onwards.

Comparing A[1 ... n] = 'EDITING' and B[1 ... m] = DISTANCE

Filling in a grid. Start at 0,0, then 0 ... n, 0 then 0, 0 ... m,
then move diagonally.

EditDistance(A, B):
	n, m = len(A), len(B)

	D(i, 0) = i for all i
	D(0, j) = j for all j

	for j from range(1, m):
		for i from range(1, n):
			insertion = D(i, j - 1) + 1
			deletion = D(i - 1, j) + 1
			match = D(i - 1, j - 1)
			mismatch = D(i - 1, j - 1) + 1

			if A[i] == B[j]:
				D(i, j) = min(insertion, deletion, match)
			else:
				D(i, j) = min(insertion, deletion, mismatch)

	return D(n, m)

# Reconstructing an Optimal Alignment
We have computed the edit distance, but how can we find an optimal alignment.

Every edge only has one previous edge. Can find path that way.

Start with last vertex. Choose arbitrary edge.

OutputAlignment(i, j):
	if i == 0 and j == 0:
		return
	if backtrack(i, j) == 'down':
		OutputAlignment(i - 1, j)
		print(str(A[i]) + '\n' + '-')
	elif backtrack(i, j) == 'right':
		OutputAlignment(i, j - 1)
		print('-' + '\n' + str(B[j]))
	else:
		OutputAlignment(i - 1, j - 1)
		print(str(A[i]) + '\n' + str(B[j]))

<>


OutputAlignment(i, j):
	if i == 0 and j == 0:
		return
	if i > 0 and D(i, j) = D(i - 1, j) + 1:
		OutputAlignment(i - 1, j)
		print(str(A[i]) + '\n' + '-')
	elif j > 0 and D(i, j) = D(i, j - 1) + 1:
		OutputAlignment(i, j - 1)
		print('-' + '\n' + str(B[j]))
	else:
		OutputAlignment(i - 1, j - 1)
		print(str(A[i]) + '\n' + str(B[j]))


# Longest Increasing Subsequence
Longest increasing subsequence: ai1, ai2, ..., aik 
s.t. i1 < i2 < ... < ik & ai1 < ai2 < ... < aik and k is maximal.

Consider the last element x of an optimal increasing
subsequence & its previous element z. 
1) z < x
2) z should be optimal end of IS sequence if array ends at z
-> subproblem: the length of an optimal IS ending a z-th element

LIS(i): optimal length of a LIS ending at A[i]
-> LIS(i) = 1 + max(LIS(j): j < i and A[j] < A[i])
-> base case: LIS(0) = 1

When we have a recurrence relation at hand, converting it to a
recursive algorithm with memorization is just a technicality.
-> Store the results in a table T: T[i] = LIS(i)

* Memorization

T = {}

def lis(A, i):
	if i not in T:
		T[i] = 1

		for j in range(i):
			if A[j] < A[i]:
				T[i] = max(T[i], lis(A, j) + 1)

	return T[i]

A = [7, 2, 1, 3, 8, 4, 9, 1, 2, 6, 5, 9, 3]
print(max(lis(A, i) for i in range(len(A))))

--> running time is quadratic (O(n**2)): there are n serious
recursive calls, each w/ needs time O(n)

* Iterative Algorithm
def lis(A):
	T = [None] * len(A)

	for i range(len(A)):
		T[i] = 1

		for j in range(i):
			if A[j] < A[i] and T[i] < T[j] + 1:
				T[i] = T[j] + 1

	return max(T[i] for i in range(len(A)))

-> important property: when computing T[i], T[j] for all j < i have already been computed
running time: O(n**2)

How to reconstruct an optimal IS?
Adjusting the algorithm:

def lis(A):
	T = [None] * len(A)
	prev = [None] * len(A)

	for i range(len(A)): # for every element in A
		T[i] = 1
		prev[i] = -1

		for j in range(i): # look at all previous elements
			if A[j] < A[i] and T[i] < T[j] + 1: # if increasing AND gives longer sequence length
				T[i] = T[j] + 1 # update sequence length
				prev[i] = j # update prev

	return max(T[i] for i in range(len(A)))

EX:
i = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
A = [7, 2, 1, 3, 8, 4, 9, 1, 2, 6, 5, 9, 3, 8, 1]
T = [1, 1, 1, 2, 3, 3, 4, 1, 2, 4, 4, 5, 3, 5, 1]
prev = [-1, -1, -1, 1, 3, 3, 4, -1, 2, 5, 5, 9, 8, 9, -1]

--> max(A) = 8, ix = 13, prev = 9
---> A -> 6, ix = 9, prev = 5
---> A -> 4, ix = 5, prev = 3
---> A -> 3, ix = 3, prev = 1
---> A -> 2, ix = 1, prev = -1

Unwinding solution

last = 0
for i in range(1, len(A)):
	if T[i] > T[last]:
		last = i

	lis = []
	current = last
	while current >= 0:
		lis.append(current)
		current = prev[current]

	lis.reverse()

	return [A[i] for i in lis]

-> This found solution by converting recursive algorithm into
iterative algorithm.

We can also brute force then optimize.

# Knapsack
Variants: fractional knapsack, discrete knapsack with / without
repetitions. Greedy algorithms only work for FRACTIONAL knapsacks.

EX: 
v = [30, 14, 16, 9]
w = [6, 3, 4, 2]
W = 10

without repeats: 6 @ 30, 4 @ 16 = $46
with repeats: 6 @ 30, 2 @ 9, 2 @ 9 = $48
fractional: 6 @ 30, 3 @ 14, 1 @ 4.5 = $48.5

# Knapsack with repetitions
Consider an optimal solution and an item in it, wi.
If we take this item out then we get an optimal solution
for a knapsack of total weight W - wi.

This knapsack has value(u) = max(value(u - wi) + vi).
value(0) = 0. Can be turned into recursive Algorithm.

Recursive Algorithm
T = dict()

def knapsack(w, v, u):
	if u not in T:
		T[u] = 0

		for i in range(len(w)):
			if w[i] <= u:
				T[u] = max(T[u],
					knapsack(w, v, u - w[i]) + v[i])

	return T[u]

w = [6, 3, 4, 2]
v = [30, 14, 16, 9]

knapsack(w, v, u = 10)

We can turn this recursive algorithm into an iterative one
by gradually filling in an array T: T[u] = value(u).

def knapsack(W, w, v):
	T = [0] * (W + 1)

	for u in range(1, W + 1): # for every capacity (increasing weight)
		for i in range(len(w)): # for every item
			if w[i] <= u: # if object fits in knapsack
				T[u] = max(T[u], T[u - w[i]] + v[i]) # is it better not to add it or to add it

	return T[W]

EX: 
knapsack(w, v, u = 10)

i = [0, 1, 2, 3,  4,  5,  6,  7,  8,  9, 10]
T = [0, 0, 9, 14, 18, 23, 30, 32, 39, 44, 48]


This has O(nW) runtime (n loop and W loop).

Alternatively, we can optimize a brute force solution.

Brute force

def knapsack(W, w, v, items = []):
	weight = sum(w[i] for i in items)
	value = sum(v[i] for i in items)

	for i in range(len(w)):
		if weight + w[i] <= W:
			value = max(value, knapsack(W, w, v, items + [i]))

	return value

The only important thing for extending the current set of 
items is the weight of this set.


# Knapsack without repetitions
If the last item is taken into an optimal solution then
what is left is an optimal solution for a knapsack of total
weight W - w_n-1 using items 0, 1, ..., n - 2.

For 0 <= u <= W and 0 <= i <= n, value(u, i) is the max
value achievable using a knapsack of weight u and the first i
items.

Base case: value(u, 0) = 0, value(0, i) = 0

For i > 0, the item i - 1 is either used or unsued:

value(u, i) = max(
				value(u - w[i - 1], i - 1) + v[i - 1],
				value(u, i -1)
				)

Recursive Algorithm
T = {}

def knapsack(w, v, u, i):
	if (u, i) not in T:
		if i == 0:
			T[u, i] = 0
		else:
			T[u, i] = knapsack(w, v, u, i - 1)

			if u >= w[i - 1]:
				T[u, i] = max(
					T[u, i], 
					knapsack(w, v, u - w[i - 1], i - 1) + v[i - 1]
					)

	return T[u, i]

Iterative Algorithm
def knapsack(w, v, u, i):
	T = [[None] * (len(w) + 1) for _ in range(W + 1)]

	for u in range(W + 1):
		T[u][0] = 0

	for i in range(1, len(w) + 1):
		for u in range(W + 1):
			T[u][i] = T[u][i - 1]

			if u >= w[i - 1]:
				T[u][i] = max(
					T[u][i], 
					T[u - w[i - 1]][i - 1] + v[i - 1]
					)

	return T[W][len(w)]

Running time: O(nW)
Space: O(nW)
Space can be improved to O(W) in the iterative version by
only storing the current column and the previous one.


Reconstructing a Solution
We can find an optimal solution be unwound by analyzing the 
computed solutions to subproblems.

Start with u = W, i = n.
If value(u, i) = value(u, i -1), then item i wasn't taken. 
Update i to i - 1 and u to u - w[i - 1].

def knapsack(W, w, v, items, last):
	weight = sum(w[i] for i in items)

	if last == len(w) - 1:
		return (sum(v[i] for i in items))

	value = knapsack(W, w, v, items, last + 1)
	if weight + w[last + 1] <= W:
		items.append(last + 1)
		value = max(value, knapsack(W, w, v, items, last + 1))
		items.pop()

	return value

print(knapsack(W = 10, w, v, items = [], last = -1))

## Alternate Explanation
W = 10, 4 items

items = [] # boolean array of size for, 1 if i is included

T[10][i] <- i is max # of items included (?)

if ith item not used, value T[W][i] = T[W][i - 1]

here, T[10][4] = 46 = T[10][3] so the 4th item wasn't used
T[10][3] = 46 > 44 = T[10][2] so the 3rd item was used
T[10][2] = 30 = T[10][1] so the 2nd item wasn't used
T[10][1] = 30 > 0 T[10][0] so the 1st item was used

item_number = [1, 2, 3, 4]
items = [1, 0, 1, 0]



Summary
* If all subproblems must be solved, an iterative algorithm is usually
faster than a recursive one bc no recursive overhead.


+3, +3, +4, -2, -4 = +4

0, 3, 6, 10, 8, 6 <- cumsum + 4 * 0 ======== remainder when % 4
4, 7, 10, 14, 12, 10 <- cumsum + 4 * 1
8, 11, 14, 18, 16, 14 <- cumsum + 4 * 2 



#### WEEK 6 ####
## DYNAMIC PROGRAMMING
# Placing Parenthesis
Consider 1 + 2 - 3 * 4 - 5. How do we place 
parentheses in an expression to maximize its value?

INPUT: a sequence of digits and a sequence of operations
OUTPUT: an order of applying those operations that max. the expression

Assume that the last operation in an optimal parenthesizing
of 5 -8 + 7 * 4 - 8 + 9 is *:
-> (5 - 8 + 7) * (4 - 8 + 9)

It would help to know the min and max values of the subexpressions
5 - 8 + 7 and 4 - 8 + 9.

min(5 - 8 + 7) = -10
max(5 - 8 + 7) = 4

min(4 - 8 + 9) = -13
max(4 - 8 + 9) = 5

maximizing the final value of the expression can be achieved here
by taking both max = -10 * -13 = 130

Let Ei,j be the subexpression d_i op_i ... op_j-1 d_j.

# Algorithm
Pseudocode:
	_min = inf
	_max = -inf

	for k from i to j - 1: # all possible splits
		a = M(i, k) opk M(k + 1, k)
		b = M(i, k) opk m(k + 1, k)
		c = m(i, k) opk M(k + 1, k)
		d = m(i, k) opk m(k + 1, k)

		_min = min(_min, a, b, c, d)
		_max = max(_max, a, b, c, d)

	return _min, _max

When computing M(i, j) the values of M(i, k) and M(k + 1, j)
should be already computed.
-> Solve all subproblems in order of increasing length, i.e., (j - i).

EX: 
Start with (1, 1), (2, 2), etc.
Move to (2, 1), (3, 2), etc.
Move to (3, 1), (4, 2), etc.

def PArentheses(d1 op1 d2 op2 ... dn):
	for i in range(1, n): # initialize min max values
		m[i, i] = di
		M[i, i] = di

	for s in range(1, n - 1):
		for i in range(1, n - s):
			j = i + s
			m[i, j], M[i, j] = MinAndMax(i, j)

	return M(1, n) # max of initial expression

Run-time is O(n**3).


expression: 5 - 8 + 7 * 4 - 8 + 9

min matrix:
5 -3 -10 -55 -63 -94
   8  15  36 -60 -195
       7  28 -28 -91
           4  -4 -13
etc

diagonal has the numbers 5, 8, 7, 4, 8, 9
diagonal above that has (5 - 8), (8 + 7), (7 * 4), etc

-> e.g., 
in m, -10 corresponds to 5 - (8 + 7)
(1, 3) corresponds to (1, 1) - (2, 3)
(1, 3) = (1, 1) - (2, 3) = 5 - 15 = - 10

could also be split as
(1, 3) = (1, 2) + (3, 3) = -3 + 7 = 4

final max value of expression is in (1, 6) = 200

# Reconstructing a Solution
Starting at max(1, 6) = 200.

(1, 6) = (1, 1) - (2, 6)

min(1,1) = max(1,1) = 5
min(2, 6) = -195
max(2, 6) = 75

-> here min(1,1) - min(2, 6) = 5 - (8 + 7 * 4 - 8 + 9)

need to figure out where min(2, 6) = -195 came from.
(2, 6) = (2, 2) + (3, 6)
and we want to minimize (2, 6), so with op + we get both min

min(2, 2) = 8
min(3, 6) = -91
but 8 - 91 != -195

so check other split, (2, 3) * (4, 6)
min(2, 3) = max(2, 3) = 15
min(4, 6) = -13
max(4, 6) = 5

min(2, 3) * min(4, 6) = 15 * (-13) = -195 !

-> 5 - ((8 + 7) * (4 - (8 + 9)))
= 5 - ((15) * (4 - (17)))
= 5 - (15 * (-13))
= 5 + 195
= 200